install.packages("nnet")
require(clusterGeneration)
 
set.seed(2)
num.vars<-8
num.obs<-1000
 
#arbitrary correlation matrix and random variables
cov.mat<-genPositiveDefMat(num.vars,covMethod=c("unifcorrmat"))$Sigma
rand.vars<-mvrnorm(num.obs,rep(0,num.vars),Sigma=cov.mat)
parms<-runif(num.vars,-10,10)
 
#response variable as linear combination of random variables and random error term
y<-rand.vars %*% matrix(parms) + rnorm(num.obs,sd=20)
require(nnet)
 
rand.vars<-data.frame(rand.vars)
y<-data.frame((y-min(y))/(max(y)-min(y)))
names(y)<-'y'
 
mod1<-nnet(rand.vars,y,size=10,linout=T)
library(readr)
library (caret)
library (e1071)
library(ggplot2)
library(GGally)
data = read.table("data_banknote_authentication.txt", sep=",")
colnames(data) <- c("variance","skewness","curtosis","entropy","genuine")
summary(data)
#setEPS()
#postscript("data_banknote.eps")
#ggpairs(data, aes(colour = genuine))
#dev.off()
data$genuine = factor(data$genuine) ##Convertir del dipo data a class.
set.seed(300)
particiones <- createDataPartition (y=data$genuine, p=0.7, list=FALSE) ## se toma el 70% del conjunto de datos para el entrenamiento
Entrenamiento <- data[particiones,] ##conjunto de entrenamiento
Prueba <- data[-particiones,]  ##conjunto de prueba
objcontrol <- trainControl(method="cv", number=10) ##El método de control es validación cruzada "Cross-Validation" y se implementa diez veces
ajuste_knn <- train(genuine ~ variance + skewness + curtosis + entropy, data = Entrenamiento, method = "knn", trControl=objcontrol, tuneLength = 10) ##Realizar el proceso de clasificación
plot(ajuste_knn) #Imprimir la exactitud obtenida con la validación cruzada.
#setEPS()
#postscript("knn_cv.eps")
#plot(knn_fit)
#dev.off(
Predicciones <- predict(ajuste_knn, newdata=Prueba)
confusionMatrix(Predicciones, Prueba$genuine)
Entrenamiento$genuine <- as.factor(Entrenamiento$genuine)
model <- train(genuine ~ ., data = Entrenamiento, method='nnet', linout=TRUE, trace = FALSE, tuneGrid=expand.grid(.size=c(1,5,10),.decay=c(0,0.001,0.1))) 
warnings()
model <- train(genuine ~ ., data = Entrenamiento, method='nnet', linout=0, trace = FALSE, tuneGrid=expand.grid(.size=c(1,5,10),.decay=c(0,0.001,0.1))) 
model
plot(model)
#import function from Github
require(RCurl)
 
root.url<-'https://gist.githubusercontent.com/fawda123'
raw.fun<-paste(
  root.url,
  '5086859/raw/cc1544804d5027d82b70e74b83b3941cd2184354/nnet_plot_fun.r',
  sep='/'
  )
script<-getURL(raw.fun, ssl.verifypeer = FALSE)
eval(parse(text = script))
rm('script','raw.fun')
par(mar=numeric(4),mfrow=c(1,2),family='serif')
plot(mod1,nid=F)
plot(mod1)
plot(model)
model
Predicciones <- predict(model, newdata=Prueba)
Predicciones
confusionMatrix(Predicciones, Prueba$genuine)
ajust_nnet <- train( genuine ~ variance + skewness + curtosis + entropy, data = Entrenamiento, method='nnet', trControl=objcontrol, linout=FALSE, trace = FALSE, tuneGrid=expand.grid(.size=c(1,5,10),.decay=c(0,0.001,0.1))) 
plot(ajust_nnet)
ajust_nnet <- train( genuine ~ variance + skewness + curtosis + entropy, data = Entrenamiento, method='nnet', trControl=objcontrol, linout=FALSE, trace = FALSE, tuneGrid=expand.grid(.size=rep(1,10,1),.decay=c(0,0.001,0.1))) 
plot(ajust_nnet)
rep(1,10,1)
rep(1,10)
ajust_nnet <- train( genuine ~ variance + skewness + curtosis + entropy, data = Entrenamiento, method='nnet', trControl=objcontrol, linout=FALSE, trace = FALSE, tuneGrid=expand.grid(.size=rep(1,10),.decay=c(0,0.001,0.1))) 
rep(1,10)
plot(ajust_nnet)
1:10
ajust_nnet <- train( genuine ~ variance + skewness + curtosis + entropy, data = Entrenamiento, method='nnet', trControl=objcontrol, linout=FALSE, trace = FALSE, tuneGrid=expand.grid(.size=c(1:10),.decay=c(0,0.001,0.1))) 
plot(ajust_nnet)
ajust_nnet$bestTune
plot(ajust_nnet$bestTune)
mod1
ajust_nnet$finalModel
plot(ajust_nnet$finalModel)
plot(ajust_nnet$finalModel)
plot(mod1)
ajust_nnet$finalModel
mod1
plot(ajust_nnet)
plot(ajust_nnet$finalModel)
plot(ajust_nnet$results )
plot(ajust_nnet$modelInfo)
ajust_nnet$modelInfo
ajust_nnet$modelInfo[1]
ajust_nnet$modelInfo$fit
ajust_nnet$bestTune
nnet(ajust_nnet$bestTune)
nnet(genuine~variance, data =Entrenamiento , ajust_nnet$bestTune)
nnet(genuine~., data =Entrenamiento , ajust_nnet$bestTune)
ajust_nnet$finalModel
plot(ajust_nnet$finalModel)
nnet(ajust_nnet$finalModel)
nnet(genuine~., data =Entrenamiento , ajust_nnet$finalModel)
plot(ajust_nnet$finalModel, nid=F)
mod1$call$data
mod1$call
ajust_nnet$results
plot(ajust_nnet)
plot(ajust_nnet)
